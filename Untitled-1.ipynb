{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data is 100 points in [0,1] inclusive regularly spaced\n",
    "train_x = torch.linspace(0, 1, 100)\n",
    "# True function is sin(2*pi*x) with Gaussian noise\n",
    "train_y = torch.sin(train_x * (2 * math.pi)) + torch.randn(train_x.size()) * math.sqrt(0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(train_x, train_y, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/100 - Loss: 0.939   lengthscale: 0.693   noise: 0.693\n",
      "Iter 2/100 - Loss: 0.907   lengthscale: 0.644   noise: 0.644\n",
      "Iter 3/100 - Loss: 0.874   lengthscale: 0.598   noise: 0.598\n",
      "Iter 4/100 - Loss: 0.836   lengthscale: 0.555   noise: 0.554\n",
      "Iter 5/100 - Loss: 0.794   lengthscale: 0.514   noise: 0.513\n",
      "Iter 6/100 - Loss: 0.746   lengthscale: 0.475   noise: 0.474\n",
      "Iter 7/100 - Loss: 0.695   lengthscale: 0.439   noise: 0.437\n",
      "Iter 8/100 - Loss: 0.644   lengthscale: 0.404   noise: 0.402\n",
      "Iter 9/100 - Loss: 0.595   lengthscale: 0.372   noise: 0.369\n",
      "Iter 10/100 - Loss: 0.550   lengthscale: 0.342   noise: 0.339\n",
      "Iter 11/100 - Loss: 0.509   lengthscale: 0.315   noise: 0.310\n",
      "Iter 12/100 - Loss: 0.472   lengthscale: 0.292   noise: 0.284\n",
      "Iter 13/100 - Loss: 0.438   lengthscale: 0.272   noise: 0.259\n",
      "Iter 14/100 - Loss: 0.404   lengthscale: 0.256   noise: 0.237\n",
      "Iter 15/100 - Loss: 0.371   lengthscale: 0.243   noise: 0.216\n",
      "Iter 16/100 - Loss: 0.339   lengthscale: 0.233   noise: 0.196\n",
      "Iter 17/100 - Loss: 0.307   lengthscale: 0.226   noise: 0.179\n",
      "Iter 18/100 - Loss: 0.275   lengthscale: 0.221   noise: 0.163\n",
      "Iter 19/100 - Loss: 0.244   lengthscale: 0.217   noise: 0.148\n",
      "Iter 20/100 - Loss: 0.213   lengthscale: 0.216   noise: 0.134\n",
      "Iter 21/100 - Loss: 0.183   lengthscale: 0.216   noise: 0.122\n",
      "Iter 22/100 - Loss: 0.154   lengthscale: 0.218   noise: 0.111\n",
      "Iter 23/100 - Loss: 0.126   lengthscale: 0.221   noise: 0.101\n",
      "Iter 24/100 - Loss: 0.100   lengthscale: 0.226   noise: 0.092\n",
      "Iter 25/100 - Loss: 0.076   lengthscale: 0.232   noise: 0.084\n",
      "Iter 26/100 - Loss: 0.054   lengthscale: 0.238   noise: 0.077\n",
      "Iter 27/100 - Loss: 0.034   lengthscale: 0.246   noise: 0.070\n",
      "Iter 28/100 - Loss: 0.018   lengthscale: 0.255   noise: 0.064\n",
      "Iter 29/100 - Loss: 0.004   lengthscale: 0.264   noise: 0.059\n",
      "Iter 30/100 - Loss: -0.007   lengthscale: 0.274   noise: 0.054\n",
      "Iter 31/100 - Loss: -0.014   lengthscale: 0.284   noise: 0.050\n",
      "Iter 32/100 - Loss: -0.019   lengthscale: 0.293   noise: 0.047\n",
      "Iter 33/100 - Loss: -0.020   lengthscale: 0.302   noise: 0.044\n",
      "Iter 34/100 - Loss: -0.019   lengthscale: 0.310   noise: 0.041\n",
      "Iter 35/100 - Loss: -0.016   lengthscale: 0.316   noise: 0.039\n",
      "Iter 36/100 - Loss: -0.012   lengthscale: 0.321   noise: 0.037\n",
      "Iter 37/100 - Loss: -0.008   lengthscale: 0.322   noise: 0.036\n",
      "Iter 38/100 - Loss: -0.004   lengthscale: 0.322   noise: 0.034\n",
      "Iter 39/100 - Loss: -0.002   lengthscale: 0.319   noise: 0.033\n",
      "Iter 40/100 - Loss: 0.000   lengthscale: 0.315   noise: 0.033\n",
      "Iter 41/100 - Loss: 0.001   lengthscale: 0.310   noise: 0.032\n",
      "Iter 42/100 - Loss: 0.001   lengthscale: 0.304   noise: 0.032\n",
      "Iter 43/100 - Loss: 0.001   lengthscale: 0.299   noise: 0.032\n",
      "Iter 44/100 - Loss: -0.001   lengthscale: 0.293   noise: 0.033\n",
      "Iter 45/100 - Loss: -0.002   lengthscale: 0.289   noise: 0.033\n",
      "Iter 46/100 - Loss: -0.005   lengthscale: 0.285   noise: 0.034\n",
      "Iter 47/100 - Loss: -0.007   lengthscale: 0.283   noise: 0.034\n",
      "Iter 48/100 - Loss: -0.010   lengthscale: 0.281   noise: 0.035\n",
      "Iter 49/100 - Loss: -0.012   lengthscale: 0.280   noise: 0.036\n",
      "Iter 50/100 - Loss: -0.014   lengthscale: 0.281   noise: 0.037\n",
      "Iter 51/100 - Loss: -0.016   lengthscale: 0.282   noise: 0.038\n",
      "Iter 52/100 - Loss: -0.018   lengthscale: 0.284   noise: 0.039\n",
      "Iter 53/100 - Loss: -0.019   lengthscale: 0.286   noise: 0.040\n",
      "Iter 54/100 - Loss: -0.020   lengthscale: 0.289   noise: 0.041\n",
      "Iter 55/100 - Loss: -0.020   lengthscale: 0.292   noise: 0.042\n",
      "Iter 56/100 - Loss: -0.021   lengthscale: 0.295   noise: 0.043\n",
      "Iter 57/100 - Loss: -0.020   lengthscale: 0.299   noise: 0.044\n",
      "Iter 58/100 - Loss: -0.020   lengthscale: 0.302   noise: 0.045\n",
      "Iter 59/100 - Loss: -0.020   lengthscale: 0.304   noise: 0.046\n",
      "Iter 60/100 - Loss: -0.019   lengthscale: 0.306   noise: 0.046\n",
      "Iter 61/100 - Loss: -0.019   lengthscale: 0.307   noise: 0.047\n",
      "Iter 62/100 - Loss: -0.018   lengthscale: 0.308   noise: 0.047\n",
      "Iter 63/100 - Loss: -0.018   lengthscale: 0.308   noise: 0.047\n",
      "Iter 64/100 - Loss: -0.018   lengthscale: 0.307   noise: 0.047\n",
      "Iter 65/100 - Loss: -0.018   lengthscale: 0.306   noise: 0.047\n",
      "Iter 66/100 - Loss: -0.018   lengthscale: 0.305   noise: 0.047\n",
      "Iter 67/100 - Loss: -0.019   lengthscale: 0.303   noise: 0.047\n",
      "Iter 68/100 - Loss: -0.019   lengthscale: 0.302   noise: 0.047\n",
      "Iter 69/100 - Loss: -0.019   lengthscale: 0.300   noise: 0.046\n",
      "Iter 70/100 - Loss: -0.019   lengthscale: 0.299   noise: 0.046\n",
      "Iter 71/100 - Loss: -0.020   lengthscale: 0.298   noise: 0.046\n",
      "Iter 72/100 - Loss: -0.020   lengthscale: 0.297   noise: 0.045\n",
      "Iter 73/100 - Loss: -0.020   lengthscale: 0.297   noise: 0.045\n",
      "Iter 74/100 - Loss: -0.020   lengthscale: 0.297   noise: 0.044\n",
      "Iter 75/100 - Loss: -0.020   lengthscale: 0.298   noise: 0.044\n",
      "Iter 76/100 - Loss: -0.021   lengthscale: 0.298   noise: 0.043\n",
      "Iter 77/100 - Loss: -0.021   lengthscale: 0.299   noise: 0.043\n",
      "Iter 78/100 - Loss: -0.021   lengthscale: 0.301   noise: 0.043\n",
      "Iter 79/100 - Loss: -0.021   lengthscale: 0.302   noise: 0.042\n",
      "Iter 80/100 - Loss: -0.021   lengthscale: 0.303   noise: 0.042\n",
      "Iter 81/100 - Loss: -0.020   lengthscale: 0.304   noise: 0.042\n",
      "Iter 82/100 - Loss: -0.020   lengthscale: 0.305   noise: 0.042\n",
      "Iter 83/100 - Loss: -0.020   lengthscale: 0.306   noise: 0.042\n",
      "Iter 84/100 - Loss: -0.020   lengthscale: 0.307   noise: 0.042\n",
      "Iter 85/100 - Loss: -0.020   lengthscale: 0.307   noise: 0.042\n",
      "Iter 86/100 - Loss: -0.020   lengthscale: 0.307   noise: 0.042\n",
      "Iter 87/100 - Loss: -0.020   lengthscale: 0.307   noise: 0.042\n",
      "Iter 88/100 - Loss: -0.020   lengthscale: 0.307   noise: 0.042\n",
      "Iter 89/100 - Loss: -0.020   lengthscale: 0.306   noise: 0.042\n",
      "Iter 90/100 - Loss: -0.020   lengthscale: 0.306   noise: 0.042\n",
      "Iter 91/100 - Loss: -0.020   lengthscale: 0.305   noise: 0.042\n",
      "Iter 92/100 - Loss: -0.021   lengthscale: 0.304   noise: 0.042\n",
      "Iter 93/100 - Loss: -0.021   lengthscale: 0.304   noise: 0.042\n",
      "Iter 94/100 - Loss: -0.021   lengthscale: 0.304   noise: 0.042\n",
      "Iter 95/100 - Loss: -0.021   lengthscale: 0.304   noise: 0.043\n",
      "Iter 96/100 - Loss: -0.021   lengthscale: 0.304   noise: 0.043\n",
      "Iter 97/100 - Loss: -0.021   lengthscale: 0.304   noise: 0.043\n",
      "Iter 98/100 - Loss: -0.021   lengthscale: 0.304   noise: 0.043\n",
      "Iter 99/100 - Loss: -0.021   lengthscale: 0.304   noise: 0.043\n",
      "Iter 100/100 - Loss: -0.021   lengthscale: 0.305   noise: 0.043\n"
     ]
    }
   ],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "#smoke_test = ('CI' in os.environ)\n",
    "training_iter = 100\n",
    "\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "        i + 1, training_iter, loss.item(),\n",
    "        model.covar_module.base_kernel.lengthscale.item(),\n",
    "        model.likelihood.noise.item()\n",
    "    ))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepchem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
